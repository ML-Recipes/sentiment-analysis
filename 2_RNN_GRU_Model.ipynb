{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "2_RNN_GRU_Model.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YBhe92eLCh0"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchtext\n",
        "import torchtext.experimental\n",
        "import torchtext.experimental.vectors\n",
        "from torchtext.experimental.datasets.raw.text_classification import RawTextIterableDataset\n",
        "from torchtext.experimental.datasets.text_classification import TextClassificationDataset\n",
        "from torchtext.experimental.functional import sequential_transforms, vocab_func, totensor\n",
        "\n",
        "import collections\n",
        "import random\n",
        "import time"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xN3iuCZILCh5"
      },
      "source": [
        "seed = 1234\n",
        "\n",
        "torch.manual_seed(seed)\n",
        "random.seed(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOYr6CiILCh9",
        "outputId": "a31bdeff-e68a-4590-e6f9-03aac551daf5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "raw_train_data, raw_test_data = torchtext.experimental.datasets.raw.IMDB()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:07<00:00, 11.6MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECyuY8NlLCiB"
      },
      "source": [
        "def get_train_valid_split(raw_train_data, split_ratio = 0.7):\n",
        "\n",
        "    raw_train_data = list(raw_train_data)\n",
        "        \n",
        "    random.shuffle(raw_train_data)\n",
        "        \n",
        "    n_train_examples = int(len(raw_train_data) * split_ratio)\n",
        "        \n",
        "    train_data = raw_train_data[:n_train_examples]\n",
        "    valid_data = raw_train_data[n_train_examples:]\n",
        "    \n",
        "    train_data = RawTextIterableDataset(train_data)\n",
        "    valid_data = RawTextIterableDataset(valid_data)\n",
        "    \n",
        "    return train_data, valid_data"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FluQaMpFLCiD"
      },
      "source": [
        "raw_train_data, raw_valid_data = get_train_valid_split(raw_train_data)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lI1YPArfLCiG"
      },
      "source": [
        "raw_train_data = list(raw_train_data)\n",
        "raw_valid_data = list(raw_valid_data)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ot2PDU5iLCiJ",
        "outputId": "66535ba5-f917-44ca-e5ff-8c89b291ff8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(f'Number of training examples: {len(raw_train_data):,}')\n",
        "print(f'Number of validation examples: {len(raw_valid_data):,}')\n",
        "print(f'Number of testing examples: {len(list(raw_test_data)):,}')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 17,500\n",
            "Number of validation examples: 7,500\n",
            "Number of testing examples: 25,000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wR6rlpL3LCiN"
      },
      "source": [
        "class Tokenizer:\n",
        "    def __init__(self, tokenize_fn = 'basic_english', lower = True, max_length = None):\n",
        "        \n",
        "        self.tokenize_fn = torchtext.data.utils.get_tokenizer(tokenize_fn)\n",
        "        self.lower = lower\n",
        "        self.max_length = max_length\n",
        "        \n",
        "    def tokenize(self, s):\n",
        "        \n",
        "        tokens = self.tokenize_fn(s)\n",
        "        \n",
        "        if self.lower:\n",
        "            tokens = [token.lower() for token in tokens]\n",
        "            \n",
        "        if self.max_length is not None:\n",
        "            tokens = tokens[:self.max_length]\n",
        "            \n",
        "        return tokens"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3OgESInLCiW"
      },
      "source": [
        "max_length = 500\n",
        "\n",
        "tokenizer = Tokenizer(max_length = max_length)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8BBbcv1LCiZ"
      },
      "source": [
        "def build_vocab_from_data(raw_data, tokenizer, **vocab_kwargs):\n",
        "    \n",
        "    token_freqs = collections.Counter()\n",
        "    \n",
        "    for label, text in raw_data:\n",
        "        tokens = tokenizer.tokenize(text)\n",
        "        token_freqs.update(tokens)\n",
        "                \n",
        "    vocab = torchtext.vocab.Vocab(token_freqs, **vocab_kwargs)\n",
        "    \n",
        "    return vocab"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzQD7kcFLCic"
      },
      "source": [
        "max_size = 25000\n",
        "\n",
        "vocab = build_vocab_from_data(raw_train_data, tokenizer, max_size = max_size)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uxxy0xwjLCie"
      },
      "source": [
        "def process_raw_data(raw_data, tokenizer, vocab):\n",
        "    \n",
        "    raw_data = [(label, text) for (label, text) in raw_data]\n",
        "\n",
        "    text_transform = sequential_transforms(tokenizer.tokenize,\n",
        "                                           vocab_func(vocab),\n",
        "                                           totensor(dtype=torch.long))\n",
        "    \n",
        "    label_transform = sequential_transforms(totensor(dtype=torch.long))\n",
        "\n",
        "    transforms = (label_transform, text_transform)\n",
        "\n",
        "    dataset = TextClassificationDataset(raw_data,\n",
        "                                        vocab,\n",
        "                                        transforms)\n",
        "    \n",
        "    return dataset"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZKZnQyyLCig"
      },
      "source": [
        "train_data = process_raw_data(raw_train_data, tokenizer, vocab)\n",
        "valid_data = process_raw_data(raw_valid_data, tokenizer, vocab)\n",
        "test_data = process_raw_data(raw_test_data, tokenizer, vocab)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YgDR-LsLCij"
      },
      "source": [
        "class Collator:\n",
        "    def __init__(self, pad_idx):\n",
        "        \n",
        "        self.pad_idx = pad_idx\n",
        "        \n",
        "    def collate(self, batch):\n",
        "        \n",
        "        labels, text = zip(*batch)\n",
        "        \n",
        "        labels = torch.LongTensor(labels)\n",
        "        \n",
        "        lengths = torch.LongTensor([len(x) for x in text])\n",
        "\n",
        "        text = nn.utils.rnn.pad_sequence(text, padding_value = self.pad_idx)\n",
        "        \n",
        "        return labels, text, lengths"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45csV4H0LCil"
      },
      "source": [
        "pad_token = '<pad>'\n",
        "pad_idx = vocab[pad_token]\n",
        "\n",
        "collator = Collator(pad_idx)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8A_T64OkLCin",
        "outputId": "74b1bd6c-4c84-494d-ceac-7f734e46a027",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(train_data))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "17500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yTjkpFGLCiq"
      },
      "source": [
        "batch_size = 256\n",
        "\n",
        "train_iterator = torch.utils.data.DataLoader(train_data, \n",
        "                                             batch_size, \n",
        "                                             shuffle = True, \n",
        "                                             collate_fn = collator.collate)\n",
        "\n",
        "valid_iterator = torch.utils.data.DataLoader(valid_data, \n",
        "                                             batch_size, \n",
        "                                             shuffle = False, \n",
        "                                             collate_fn = collator.collate)\n",
        "\n",
        "test_iterator = torch.utils.data.DataLoader(test_data, \n",
        "                                            batch_size, \n",
        "                                            shuffle = False, \n",
        "                                            collate_fn = collator.collate)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ez7ZyjqLCis"
      },
      "source": [
        "class GRU(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hid_dim, output_dim, pad_idx):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim, padding_idx = pad_idx)\n",
        "        self.gru = nn.GRU(emb_dim, hid_dim)\n",
        "        self.fc = nn.Linear(hid_dim, output_dim)\n",
        "\n",
        "    def forward(self, text, lengths):\n",
        "\n",
        "        # text = [seq len, batch size]\n",
        "        # lengths = [batch size]\n",
        "\n",
        "        embedded = self.embedding(text)\n",
        "\n",
        "        # embedded = [seq len, batch size, emb dim]\n",
        "\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, lengths, enforce_sorted = False)\n",
        "\n",
        "        packed_output, hidden = self.gru(packed_embedded)\n",
        "\n",
        "        output, _ = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
        "\n",
        "        # output = [seq_len, batch size, n directions * hid dim]\n",
        "        # hidden = [n layers * n directions, batch size, hid dim]\n",
        "\n",
        "        prediction = self.fc(hidden.squeeze(0))\n",
        "\n",
        "        # prediction = [batch size, output dim]\n",
        "\n",
        "        return prediction"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhVs1JOKLCiv"
      },
      "source": [
        "input_dim = len(vocab)\n",
        "emb_dim = 100\n",
        "hid_dim = 256\n",
        "output_dim = 2\n",
        "\n",
        "model = GRU(input_dim, emb_dim, hid_dim, output_dim, pad_idx)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xyx9BAALCix",
        "outputId": "164d4cf3-d76d-4680-9241-23caba96b290",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(vocab))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25002\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDkc0IIwLCiz"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74HAnM1rLCi1",
        "outputId": "5213687e-cf4c-4929-e992-1865c7bf8fcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 2,775,658 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jk8zYrN6LCi4",
        "outputId": "58eca0b0-c8a0-4d3c-b595-3238832536db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "model.parameters"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Module.parameters of GRU(\n",
              "  (embedding): Embedding(25002, 100, padding_idx=1)\n",
              "  (gru): GRU(100, 256)\n",
              "  (fc): Linear(in_features=256, out_features=2, bias=True)\n",
              ")>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-cjmGWDLCi6",
        "outputId": "bca2446a-6018-4c47-8188-03b6d1dcadd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "for n, p in model.named_parameters():\n",
        "    print(f'name: {n}, shape: {p.shape}')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "name: embedding.weight, shape: torch.Size([25002, 100])\n",
            "name: gru.weight_ih_l0, shape: torch.Size([768, 100])\n",
            "name: gru.weight_hh_l0, shape: torch.Size([768, 256])\n",
            "name: gru.bias_ih_l0, shape: torch.Size([768])\n",
            "name: gru.bias_hh_l0, shape: torch.Size([768])\n",
            "name: fc.weight, shape: torch.Size([2, 256])\n",
            "name: fc.bias, shape: torch.Size([2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0Kphg65LCi8"
      },
      "source": [
        "def initialize_parameters(m):\n",
        "    if isinstance(m, nn.Embedding):\n",
        "        nn.init.uniform_(m.weight, -0.05, 0.05)\n",
        "    elif isinstance(m, nn.GRU):\n",
        "        for n, p in m.named_parameters():\n",
        "            if 'weight_ih' in n:\n",
        "                r, z, n = p.chunk(3)\n",
        "                nn.init.xavier_uniform_(r)\n",
        "                nn.init.xavier_uniform_(z)\n",
        "                nn.init.xavier_uniform_(n)\n",
        "            elif 'weight_hh' in n:\n",
        "                r, z, n = p.chunk(3)\n",
        "                nn.init.orthogonal_(r)\n",
        "                nn.init.orthogonal_(z)\n",
        "                nn.init.orthogonal_(n)\n",
        "            elif 'bias' in n:\n",
        "                r, z, n = p.chunk(3)\n",
        "                nn.init.zeros_(r)\n",
        "                nn.init.zeros_(z)\n",
        "                nn.init.zeros_(n)\n",
        "    elif isinstance(m, nn.Linear):\n",
        "        nn.init.xavier_uniform_(m.weight)\n",
        "        nn.init.zeros_(m.bias)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onQaZP7-LCi-",
        "outputId": "2b4e7709-4dae-4cc4-9751-4ea068913cae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "model.apply(initialize_parameters)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GRU(\n",
              "  (embedding): Embedding(25002, 100, padding_idx=1)\n",
              "  (gru): GRU(100, 256)\n",
              "  (fc): Linear(in_features=256, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNEtlZ9-LCjB",
        "outputId": "6c6dd5bd-777f-49e2-cd7c-76b9aafed4c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "glove = torchtext.experimental.vectors.GloVe(name = '6B',\n",
        "                                             dim = emb_dim)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "glove.6B.zip: 100%|██████████| 862M/862M [06:29<00:00, 2.21MB/s]\n",
            "100%|██████████| 400000/400000 [00:22<00:00, 17488.22lines/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqBnelfbLCjD"
      },
      "source": [
        "def get_pretrained_embedding(initial_embedding, pretrained_vectors, vocab, unk_token):\n",
        "    \n",
        "    pretrained_embedding = torch.FloatTensor(initial_embedding.weight.clone()).detach()    \n",
        "    #pretrained_vocab = pretrained_vectors.vectors.get_stoi()\n",
        "    \n",
        "    unk_tokens = []\n",
        "    \n",
        "    for idx, token in enumerate(vocab.itos):\n",
        "        #if token in pretrained_vocab:\n",
        "        pretrained_vector = pretrained_vectors[token]\n",
        "        pretrained_embedding[idx] = pretrained_vector\n",
        "        #else:\n",
        "        #    unk_tokens.append(token)\n",
        "        \n",
        "    return pretrained_embedding, unk_tokens"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIHSHsNsLCjF"
      },
      "source": [
        "unk_token = '<unk>'\n",
        "\n",
        "pretrained_embedding, unk_tokens = get_pretrained_embedding(model.embedding, glove, vocab, unk_token)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fF-E6ym7LCjH",
        "outputId": "a6389377-296b-467d-af4c-9daaa3e993f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "model.embedding.weight.data.copy_(pretrained_embedding)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
              "        ...,\n",
              "        [-0.2925,  0.1087,  0.7920,  ..., -0.3641,  0.1822, -0.4104],\n",
              "        [-0.7250,  0.7545,  0.1637,  ..., -0.0144, -0.1761,  0.3418],\n",
              "        [ 1.1753,  0.0460, -0.3542,  ...,  0.4510,  0.0485, -0.4015]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66o28bzdLCjJ"
      },
      "source": [
        "model.embedding.weight.data[pad_idx] = torch.zeros(emb_dim)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLaYefUgLCjM",
        "outputId": "fb39c02a-d046-4fd4-c983-dd460ea6226e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "model.embedding.weight.data"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
              "        ...,\n",
              "        [-0.2925,  0.1087,  0.7920,  ..., -0.3641,  0.1822, -0.4104],\n",
              "        [-0.7250,  0.7545,  0.1637,  ..., -0.0144, -0.1761,  0.3418],\n",
              "        [ 1.1753,  0.0460, -0.3542,  ...,  0.4510,  0.0485, -0.4015]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZVOlNpBLCjO"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters())"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmcV4zkqLCjP"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmwTR30PLCjR"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wS6EBGXULCjT"
      },
      "source": [
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-3Qpc0pLCjV"
      },
      "source": [
        "def calculate_accuracy(predictions, labels):\n",
        "    top_predictions = predictions.argmax(1, keepdim = True)\n",
        "    correct = top_predictions.eq(labels.view_as(top_predictions)).sum()\n",
        "    accuracy = correct.float() / labels.shape[0]\n",
        "    return accuracy"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nt5KRQFaLCjX"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion, device):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for labels, text, lengths in iterator:\n",
        "        \n",
        "        labels = labels.to(device)\n",
        "        text = text.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        predictions = model(text, lengths)\n",
        "        \n",
        "        loss = criterion(predictions, labels)\n",
        "        \n",
        "        acc = calculate_accuracy(predictions, labels)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLL2GkzfLCjZ"
      },
      "source": [
        "def evaluate(model, iterator, criterion, device):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for labels, text, lengths in iterator:\n",
        "\n",
        "            labels = labels.to(device)\n",
        "            text = text.to(device)\n",
        "            \n",
        "            predictions = model(text, lengths)\n",
        "            \n",
        "            loss = criterion(predictions, labels)\n",
        "            \n",
        "            acc = calculate_accuracy(predictions, labels)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lje3cMR0LCjb"
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Foc0FHu1LCjf",
        "outputId": "655b6526-52e8-4dcb-82ac-5e058244d112",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "n_epochs = 10\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "\n",
        "    start_time = time.monotonic()\n",
        "    \n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion, device)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion, device)\n",
        "    \n",
        "    end_time = time.monotonic()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'gru-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 22s\n",
            "\tTrain Loss: 0.654 | Train Acc: 60.74%\n",
            "\t Val. Loss: 0.582 |  Val. Acc: 69.12%\n",
            "Epoch: 02 | Epoch Time: 0m 21s\n",
            "\tTrain Loss: 0.402 | Train Acc: 82.11%\n",
            "\t Val. Loss: 0.335 |  Val. Acc: 86.29%\n",
            "Epoch: 03 | Epoch Time: 0m 21s\n",
            "\tTrain Loss: 0.251 | Train Acc: 90.12%\n",
            "\t Val. Loss: 0.283 |  Val. Acc: 88.57%\n",
            "Epoch: 04 | Epoch Time: 0m 21s\n",
            "\tTrain Loss: 0.181 | Train Acc: 93.25%\n",
            "\t Val. Loss: 0.291 |  Val. Acc: 89.49%\n",
            "Epoch: 05 | Epoch Time: 0m 21s\n",
            "\tTrain Loss: 0.113 | Train Acc: 96.18%\n",
            "\t Val. Loss: 0.329 |  Val. Acc: 89.25%\n",
            "Epoch: 06 | Epoch Time: 0m 21s\n",
            "\tTrain Loss: 0.065 | Train Acc: 97.96%\n",
            "\t Val. Loss: 0.363 |  Val. Acc: 89.41%\n",
            "Epoch: 07 | Epoch Time: 0m 21s\n",
            "\tTrain Loss: 0.036 | Train Acc: 99.04%\n",
            "\t Val. Loss: 0.417 |  Val. Acc: 89.24%\n",
            "Epoch: 08 | Epoch Time: 0m 21s\n",
            "\tTrain Loss: 0.018 | Train Acc: 99.60%\n",
            "\t Val. Loss: 0.466 |  Val. Acc: 88.96%\n",
            "Epoch: 09 | Epoch Time: 0m 21s\n",
            "\tTrain Loss: 0.014 | Train Acc: 99.68%\n",
            "\t Val. Loss: 0.592 |  Val. Acc: 88.63%\n",
            "Epoch: 10 | Epoch Time: 0m 21s\n",
            "\tTrain Loss: 0.008 | Train Acc: 99.81%\n",
            "\t Val. Loss: 0.649 |  Val. Acc: 88.17%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkalrwfTLCji",
        "outputId": "a5b1784f-0380-4b10-cf7a-a71d6ccf4c1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        }
      },
      "source": [
        "model.load_state_dict(torch.load('gru-model.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion, device)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ZeroDivisionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-465fedec71e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gru-model.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-39-466894d135d9>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, iterator, criterion, device)\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mepoch_acc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mepoch_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_acc\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_zaza8tR_pP"
      },
      "source": [
        "def predict_sentiment(tokenizer, vocab, model, device, sentence):\n",
        "    model.eval()\n",
        "    tokens = tokenizer.tokenize(sentence)\n",
        "    length = torch.LongTensor([len(tokens)]).to(device)\n",
        "    indexes = [vocab.stoi[token] for token in tokens]\n",
        "    tensor = torch.LongTensor(indexes).unsqueeze(-1).to(device)\n",
        "    prediction = model(tensor, length)\n",
        "    probabilities = nn.functional.softmax(prediction, dim = -1)\n",
        "    pos_probability = probabilities.squeeze()[-1].item()\n",
        "    return pos_probability"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkBRbebbSBs8",
        "outputId": "6a2b3372-5418-40a9-8fe6-1c1d57c29c82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sentence = 'the absolute worst movie of all time.'\n",
        "\n",
        "predict_sentiment(tokenizer, vocab, model, device, sentence)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.06924265623092651"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bovmswASEOe",
        "outputId": "3bcbf364-d8d8-44cc-af99-90f3bc56e2bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sentence = 'one of the greatest films i have ever seen in my life.'\n",
        "\n",
        "predict_sentiment(tokenizer, vocab, model, device, sentence)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8531287908554077"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdO9bE2bSHVJ",
        "outputId": "96950a98-6958-444b-de8a-b260a09c2310",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sentence = \"i thought it was going to be one of the greatest films i have ever seen in my life, \\\n",
        "but it was actually the absolute worst movie of all time.\"\n",
        "\n",
        "predict_sentiment(tokenizer, vocab, model, device, sentence)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.16504435241222382"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woXCP0zCSJ9O",
        "outputId": "ab86b202-7ba2-402e-97d7-dad3646c6bfd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sentence = \"i thought it was going to be the absolute worst movie of all time, \\\n",
        "but it was actually one of the greatest films i have ever seen in my life.\"\n",
        "\n",
        "predict_sentiment(tokenizer, vocab, model, device, sentence)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.36099088191986084"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    }
  ]
}