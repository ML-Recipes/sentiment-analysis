{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3_RNN_BiLSTM",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-c5s2pGcLUpG"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchtext\n",
        "import torchtext.experimental\n",
        "import torchtext.experimental.vectors\n",
        "from torchtext.experimental.datasets.raw.text_classification import RawTextIterableDataset\n",
        "from torchtext.experimental.datasets.text_classification import TextClassificationDataset\n",
        "from torchtext.experimental.functional import sequential_transforms, vocab_func, totensor\n",
        "\n",
        "import collections\n",
        "import random\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWyvD8UiWBR4"
      },
      "source": [
        "seed = 1234\n",
        "\n",
        "torch.manual_seed(seed)\n",
        "random.seed(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7BMHTChXIlH",
        "outputId": "76cbcb06-5830-4531-d03e-50a39d156d5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "raw_train_data, raw_test_data = torchtext.experimental.datasets.raw.IMDB()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:01<00:00, 50.3MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GURhpprXLMt"
      },
      "source": [
        "def get_train_valid_split(raw_train_data, split_ratio = 0.7):\n",
        "\n",
        "    raw_train_data = list(raw_train_data)\n",
        "        \n",
        "    random.shuffle(raw_train_data)\n",
        "        \n",
        "    n_train_examples = int(len(raw_train_data) * split_ratio)\n",
        "        \n",
        "    train_data = raw_train_data[:n_train_examples]\n",
        "    valid_data = raw_train_data[n_train_examples:]\n",
        "    \n",
        "    train_data = RawTextIterableDataset(train_data)\n",
        "    valid_data = RawTextIterableDataset(valid_data)\n",
        "    \n",
        "    return train_data, valid_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJLwMzTNXNfs"
      },
      "source": [
        "raw_train_data, raw_valid_data = get_train_valid_split(raw_train_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nus2fc1oXP-l"
      },
      "source": [
        "raw_train_data = list(raw_train_data)\n",
        "raw_valid_data = list(raw_valid_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6c-8MRwIXSto",
        "outputId": "4eecef95-9f34-4e8b-d1dd-102681fdf3c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(f'Number of training examples: {len(raw_train_data):,}')\n",
        "print(f'Number of validation examples: {len(raw_valid_data):,}')\n",
        "print(f'Number of testing examples: {len(list(raw_test_data)):,}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 17,500\n",
            "Number of validation examples: 7,500\n",
            "Number of testing examples: 25,000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFdC4ESvXU2H"
      },
      "source": [
        "class Tokenizer:\n",
        "    def __init__(self, tokenize_fn = 'basic_english', lower = True, max_length = None):\n",
        "        \n",
        "        self.tokenize_fn = torchtext.data.utils.get_tokenizer(tokenize_fn)\n",
        "        self.lower = lower\n",
        "        self.max_length = max_length\n",
        "        \n",
        "    def tokenize(self, s):\n",
        "        \n",
        "        tokens = self.tokenize_fn(s)\n",
        "        \n",
        "        if self.lower:\n",
        "            tokens = [token.lower() for token in tokens]\n",
        "            \n",
        "        if self.max_length is not None:\n",
        "            tokens = tokens[:self.max_length]\n",
        "            \n",
        "        return tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98tub_4LXWtH"
      },
      "source": [
        "max_length = 500\n",
        "\n",
        "tokenizer = Tokenizer(max_length = max_length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-nOrz7wXYQ5"
      },
      "source": [
        "def build_vocab_from_data(raw_data, tokenizer, **vocab_kwargs):\n",
        "    \n",
        "    token_freqs = collections.Counter()\n",
        "    \n",
        "    for label, text in raw_data:\n",
        "        tokens = tokenizer.tokenize(text)\n",
        "        token_freqs.update(tokens)\n",
        "                \n",
        "    vocab = torchtext.vocab.Vocab(token_freqs, **vocab_kwargs)\n",
        "    \n",
        "    return vocab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwjTB49uXZw-"
      },
      "source": [
        "max_size = 25000\n",
        "\n",
        "vocab = build_vocab_from_data(raw_train_data, tokenizer, max_size = max_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrOD5Ge0Xbb1"
      },
      "source": [
        "def process_raw_data(raw_data, tokenizer, vocab):\n",
        "    \n",
        "    raw_data = [(label, text) for (label, text) in raw_data]\n",
        "\n",
        "    text_transform = sequential_transforms(tokenizer.tokenize,\n",
        "                                           vocab_func(vocab),\n",
        "                                           totensor(dtype=torch.long))\n",
        "    \n",
        "    label_transform = sequential_transforms(totensor(dtype=torch.long))\n",
        "\n",
        "    transforms = (label_transform, text_transform)\n",
        "\n",
        "    dataset = TextClassificationDataset(raw_data,\n",
        "                                        vocab,\n",
        "                                        transforms)\n",
        "    \n",
        "    return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMiie1-_XdSA"
      },
      "source": [
        "train_data = process_raw_data(raw_train_data, tokenizer, vocab)\n",
        "valid_data = process_raw_data(raw_valid_data, tokenizer, vocab)\n",
        "test_data = process_raw_data(raw_test_data, tokenizer, vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NQKZcb2XenY"
      },
      "source": [
        "class Collator:\n",
        "    def __init__(self, pad_idx):\n",
        "        \n",
        "        self.pad_idx = pad_idx\n",
        "        \n",
        "    def collate(self, batch):\n",
        "        \n",
        "        labels, text = zip(*batch)\n",
        "        \n",
        "        labels = torch.LongTensor(labels)\n",
        "        \n",
        "        lengths = torch.LongTensor([len(x) for x in text])\n",
        "\n",
        "        text = nn.utils.rnn.pad_sequence(text, padding_value = self.pad_idx)\n",
        "        \n",
        "        return labels, text, lengths"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoUUBVDjXgIe"
      },
      "source": [
        "pad_token = '<pad>'\n",
        "pad_idx = vocab[pad_token]\n",
        "\n",
        "collator = Collator(pad_idx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBGI7NUnXhsk",
        "outputId": "ed8e9117-1dff-4753-8086-cad557a193ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(train_data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "17500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPURblDpXjRB"
      },
      "source": [
        "batch_size = 256\n",
        "\n",
        "train_iterator = torch.utils.data.DataLoader(train_data, \n",
        "                                             batch_size, \n",
        "                                             shuffle = True, \n",
        "                                             collate_fn = collator.collate)\n",
        "\n",
        "valid_iterator = torch.utils.data.DataLoader(valid_data, \n",
        "                                             batch_size, \n",
        "                                             shuffle = False, \n",
        "                                             collate_fn = collator.collate)\n",
        "\n",
        "test_iterator = torch.utils.data.DataLoader(test_data, \n",
        "                                            batch_size, \n",
        "                                            shuffle = False, \n",
        "                                            collate_fn = collator.collate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcOAFDpPXlJ2"
      },
      "source": [
        "class GRU(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hid_dim, output_dim, pad_idx):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim, padding_idx = pad_idx)\n",
        "        self.gru = nn.GRU(emb_dim, hid_dim)\n",
        "        self.fc = nn.Linear(hid_dim, output_dim)\n",
        "\n",
        "    def forward(self, text, lengths):\n",
        "\n",
        "        # text = [seq len, batch size]\n",
        "        # lengths = [batch size]\n",
        "\n",
        "        embedded = self.embedding(text)\n",
        "\n",
        "        # embedded = [seq len, batch size, emb dim]\n",
        "\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, lengths, enforce_sorted = False)\n",
        "\n",
        "        packed_output, hidden = self.gru(packed_embedded)\n",
        "\n",
        "        output, _ = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
        "\n",
        "        # output = [seq_len, batch size, n directions * hid dim]\n",
        "        # hidden = [n layers * n directions, batch size, hid dim]\n",
        "\n",
        "        prediction = self.fc(hidden.squeeze(0))\n",
        "\n",
        "        # prediction = [batch size, output dim]\n",
        "\n",
        "        return prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsP8rtcCXm67"
      },
      "source": [
        "input_dim = len(vocab)\n",
        "emb_dim = 100\n",
        "hid_dim = 256\n",
        "output_dim = 2\n",
        "\n",
        "model = GRU(input_dim, emb_dim, hid_dim, output_dim, pad_idx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mzru111qXoSM",
        "outputId": "54005478-d719-4750-f661-f1d0b4abdc1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(vocab))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25002\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQNQuVXEXqQ4"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uq9zObtCXq3x",
        "outputId": "9f1dc448-f790-4664-b35c-02df5263cb27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 2,775,658 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1UvovckXsap",
        "outputId": "b2f383e7-56f1-4829-875e-b47adbe3e7ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "model.parameters"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Module.parameters of GRU(\n",
              "  (embedding): Embedding(25002, 100, padding_idx=1)\n",
              "  (gru): GRU(100, 256)\n",
              "  (fc): Linear(in_features=256, out_features=2, bias=True)\n",
              ")>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qULvGNPOXuM4",
        "outputId": "7cd5196e-0290-4ade-e360-38fa4d0fe1b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "for n, p in model.named_parameters():\n",
        "    print(f'name: {n}, shape: {p.shape}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "name: embedding.weight, shape: torch.Size([25002, 100])\n",
            "name: gru.weight_ih_l0, shape: torch.Size([768, 100])\n",
            "name: gru.weight_hh_l0, shape: torch.Size([768, 256])\n",
            "name: gru.bias_ih_l0, shape: torch.Size([768])\n",
            "name: gru.bias_hh_l0, shape: torch.Size([768])\n",
            "name: fc.weight, shape: torch.Size([2, 256])\n",
            "name: fc.bias, shape: torch.Size([2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reZU6R_9Xv6n"
      },
      "source": [
        "def initialize_parameters(m):\n",
        "    if isinstance(m, nn.Embedding):\n",
        "        nn.init.uniform_(m.weight, -0.05, 0.05)\n",
        "    elif isinstance(m, nn.GRU):\n",
        "        for n, p in m.named_parameters():\n",
        "            if 'weight_ih' in n:\n",
        "                r, z, n = p.chunk(3)\n",
        "                nn.init.xavier_uniform_(r)\n",
        "                nn.init.xavier_uniform_(z)\n",
        "                nn.init.xavier_uniform_(n)\n",
        "            elif 'weight_hh' in n:\n",
        "                r, z, n = p.chunk(3)\n",
        "                nn.init.orthogonal_(r)\n",
        "                nn.init.orthogonal_(z)\n",
        "                nn.init.orthogonal_(n)\n",
        "            elif 'bias' in n:\n",
        "                r, z, n = p.chunk(3)\n",
        "                nn.init.zeros_(r)\n",
        "                nn.init.zeros_(z)\n",
        "                nn.init.zeros_(n)\n",
        "    elif isinstance(m, nn.Linear):\n",
        "        nn.init.xavier_uniform_(m.weight)\n",
        "        nn.init.zeros_(m.bias)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkLfydJrXyK6",
        "outputId": "00b05745-0399-4fa5-fd3f-1bbd002bfc6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "model.apply(initialize_parameters)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GRU(\n",
              "  (embedding): Embedding(25002, 100, padding_idx=1)\n",
              "  (gru): GRU(100, 256)\n",
              "  (fc): Linear(in_features=256, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJzSNfFPXz9A",
        "outputId": "420068f2-c027-4dcd-f1ad-f0a6c75ed835",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "glove = torchtext.experimental.vectors.GloVe(name = '6B',\n",
        "                                             dim = emb_dim)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "glove.6B.zip: 100%|██████████| 862M/862M [06:26<00:00, 2.23MB/s]\n",
            "100%|██████████| 400000/400000 [00:14<00:00, 27253.97lines/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21r3QJGxa9HV",
        "outputId": "b27bf6c5-d4f8-48c8-9476-b11e69a0baab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(glove['ai'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h10ht1Ala-YD",
        "outputId": "2b65744e-266a-4a27-ac78-06b83e9bfabb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        }
      },
      "source": [
        "glove_vocab = glove.vectors.get_stoi()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-91127ebc08e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mglove_vocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglove\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_stoi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: __torch__.torch.classes.torchtext.Vectors does not have a field with name 'get_stoi'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLudlGO3wkZI"
      },
      "source": [
        "examples = ['chip', 'baby', 'beautiful']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZAKNZZEwl8I",
        "outputId": "caf6fa17-232f-4051-e422-06bfb718273a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "glove[' ก']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiqUTphxZKSq"
      },
      "source": [
        "def get_pretrained_embedding(initial_embedding, pretrained_vectors, vocab, unk_token):\n",
        "    \n",
        "    pretrained_embedding = torch.FloatTensor(initial_embedding.weight.clone()).detach()    \n",
        "    #pretrained_vocab = pretrained_vectors.vectors.get_stoi()\n",
        "    \n",
        "    unk_tokens = []\n",
        "    \n",
        "    for idx, token in enumerate(vocab.itos):\n",
        "        #if token in pretrained_vocab:\n",
        "        pretrained_vector = pretrained_vectors[token]\n",
        "        pretrained_embedding[idx] = pretrained_vector\n",
        "        #else:\n",
        "        #    unk_tokens.append(token)\n",
        "        \n",
        "    return pretrained_embedding, unk_tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6z79Vs_Zk1u"
      },
      "source": [
        "unk_token = '<unk>'\n",
        "\n",
        "pretrained_embedding, unk_tokens = get_pretrained_embedding(model.embedding, glove, vocab, unk_token)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mR49wUIZoyL",
        "outputId": "989598f3-a00d-4ad1-8a3c-044be4e6ded5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "model.embedding.weight.data.copy_(pretrained_embedding)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
              "        ...,\n",
              "        [-0.2925,  0.1087,  0.7920,  ..., -0.3641,  0.1822, -0.4104],\n",
              "        [-0.7250,  0.7545,  0.1637,  ..., -0.0144, -0.1761,  0.3418],\n",
              "        [ 1.1753,  0.0460, -0.3542,  ...,  0.4510,  0.0485, -0.4015]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSC0yW_40DN5"
      },
      "source": [
        "model.embedding.weight.data[pad_idx] = torch.zeros(emb_dim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1VLDWZ10GWO"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ybQDYhf0JIV"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_T49Smbw0J45"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gq_fK_RK0LiZ"
      },
      "source": [
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOxkyPzH0NLO"
      },
      "source": [
        "def calculate_accuracy(predictions, labels):\n",
        "    top_predictions = predictions.argmax(1, keepdim = True)\n",
        "    correct = top_predictions.eq(labels.view_as(top_predictions)).sum()\n",
        "    accuracy = correct.float() / labels.shape[0]\n",
        "    return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STYIvhry0RRq"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion, device):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for labels, text, lengths in iterator:\n",
        "        \n",
        "        labels = labels.to(device)\n",
        "        text = text.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        predictions = model(text, lengths)\n",
        "        \n",
        "        loss = criterion(predictions, labels)\n",
        "        \n",
        "        acc = calculate_accuracy(predictions, labels)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nc8Z5vak0TB8"
      },
      "source": [
        "def evaluate(model, iterator, criterion, device):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for labels, text, lengths in iterator:\n",
        "\n",
        "            labels = labels.to(device)\n",
        "            text = text.to(device)\n",
        "            \n",
        "            predictions = model(text, lengths)\n",
        "            \n",
        "            loss = criterion(predictions, labels)\n",
        "            \n",
        "            acc = calculate_accuracy(predictions, labels)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5poxPKFt0U6D"
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZGFKXwF0WMD",
        "outputId": "8939db2e-df42-4b93-b5db-6e938a6c59ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "n_epochs = 10\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "\n",
        "    start_time = time.monotonic()\n",
        "    \n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion, device)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion, device)\n",
        "    \n",
        "    end_time = time.monotonic()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'bilstm-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 12s\n",
            "\tTrain Loss: 0.654 | Train Acc: 60.74%\n",
            "\t Val. Loss: 0.582 |  Val. Acc: 69.12%\n",
            "Epoch: 02 | Epoch Time: 0m 11s\n",
            "\tTrain Loss: 0.402 | Train Acc: 82.10%\n",
            "\t Val. Loss: 0.335 |  Val. Acc: 86.32%\n",
            "Epoch: 03 | Epoch Time: 0m 11s\n",
            "\tTrain Loss: 0.251 | Train Acc: 90.10%\n",
            "\t Val. Loss: 0.283 |  Val. Acc: 88.59%\n",
            "Epoch: 04 | Epoch Time: 0m 11s\n",
            "\tTrain Loss: 0.181 | Train Acc: 93.25%\n",
            "\t Val. Loss: 0.290 |  Val. Acc: 89.48%\n",
            "Epoch: 05 | Epoch Time: 0m 11s\n",
            "\tTrain Loss: 0.113 | Train Acc: 96.18%\n",
            "\t Val. Loss: 0.329 |  Val. Acc: 89.25%\n",
            "Epoch: 06 | Epoch Time: 0m 11s\n",
            "\tTrain Loss: 0.065 | Train Acc: 97.96%\n",
            "\t Val. Loss: 0.363 |  Val. Acc: 89.45%\n",
            "Epoch: 07 | Epoch Time: 0m 11s\n",
            "\tTrain Loss: 0.036 | Train Acc: 99.03%\n",
            "\t Val. Loss: 0.417 |  Val. Acc: 89.21%\n",
            "Epoch: 08 | Epoch Time: 0m 11s\n",
            "\tTrain Loss: 0.019 | Train Acc: 99.55%\n",
            "\t Val. Loss: 0.476 |  Val. Acc: 89.12%\n",
            "Epoch: 09 | Epoch Time: 0m 11s\n",
            "\tTrain Loss: 0.010 | Train Acc: 99.80%\n",
            "\t Val. Loss: 0.609 |  Val. Acc: 87.65%\n",
            "Epoch: 10 | Epoch Time: 0m 11s\n",
            "\tTrain Loss: 0.008 | Train Acc: 99.81%\n",
            "\t Val. Loss: 0.588 |  Val. Acc: 89.12%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_26HvSo1cYR",
        "outputId": "ada5672a-8007-4d40-a28b-6b02c24f9313",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        }
      },
      "source": [
        "model.load_state_dict(torch.load('bilstm-model.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion, device)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ZeroDivisionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-aa367f5afee5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bilstm-model.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-56-466894d135d9>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, iterator, criterion, device)\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mepoch_acc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mepoch_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_acc\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEnSRU8d2F7T"
      },
      "source": [
        "def predict_sentiment(tokenizer, vocab, model, device, sentence):\n",
        "    model.eval()\n",
        "    tokens = tokenizer.tokenize(sentence)\n",
        "    length = torch.LongTensor([len(tokens)]).to(device)\n",
        "    indexes = [vocab.stoi[token] for token in tokens]\n",
        "    tensor = torch.LongTensor(indexes).unsqueeze(-1).to(device)\n",
        "    prediction = model(tensor, length)\n",
        "    probabilities = nn.functional.softmax(prediction, dim = -1)\n",
        "    pos_probability = probabilities.squeeze()[-1].item()\n",
        "    return pos_probability"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMcCTihY2G2p",
        "outputId": "099a2a28-c81f-41f2-db00-78c0cb6b1262",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sentence = 'the absolute worst movie of all time.'\n",
        "\n",
        "predict_sentiment(tokenizer, vocab, model, device, sentence)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.06930574029684067"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMdO3Dkf2Pss",
        "outputId": "9b427dfe-a2b7-4a04-d9b0-40c144dff51b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sentence = 'one of the greatest films i have ever seen in my life.'\n",
        "\n",
        "predict_sentiment(tokenizer, vocab, model, device, sentence)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8534165620803833"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZTugjWz2SHV",
        "outputId": "d9858e2e-0586-4a31-ed6c-29d816a28d74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sentence = \"i thought it was going to be one of the greatest films i have ever seen in my life, \\\n",
        "but it was actually the absolute worst movie of all time.\"\n",
        "\n",
        "predict_sentiment(tokenizer, vocab, model, device, sentence)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.16531729698181152"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1YF3sZ92UUI",
        "outputId": "76c262d6-887c-44d4-daa4-1977b80566a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sentence = \"i thought it was going to be the absolute worst movie of all time, \\\n",
        "but it was actually one of the greatest films i have ever seen in my life.\"\n",
        "\n",
        "predict_sentiment(tokenizer, vocab, model, device, sentence)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3613453805446625"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    }
  ]
}